# README ‚Äî Teste Intuitive Care

**Projeto:** teste-intuitive-care  
**Autor:** Josu√© Ara√∫jo Saraiva

---

Ol√°! üëã  
Este reposit√≥rio cont√©m minha solu√ß√£o para o **Teste de Est√°gio** da **Intuitive Care**.

Busquei resolver o desafio de forma **pragm√°tica**, justificando **trade-offs t√©cnicos** e organizando um fluxo **execut√°vel de ponta a ponta**, do download de dados √† interface web.

> **Nota:** Para entregar a melhor solu√ß√£o poss√≠vel, adquiri um curso na Udemy e estudei por 2 dias as tecnologias envolvidas (Python, FastAPI, Vue 3, SQL e processamento de dados).

---

## ‚úÖ Vis√£o Geral do Projeto

O projeto est√° dividido em:

- **Backend (Python + FastAPI)**: API para consulta das operadoras, hist√≥rico e estat√≠sticas  
- **Pipeline de Dados (Python)**: download, extra√ß√£o, limpeza, consolida√ß√£o e agrega√ß√£o  
- **Banco de Dados (PostgreSQL)**: modelagem normalizada, scripts de carga e queries anal√≠ticas  
- **Frontend (Vue 3 + Vite)**: listagem, busca, pagina√ß√£o, gr√°ficos e detalhes  

---

## üìÅ Organiza√ß√£o de Pastas

```text
TESTE_INTUITIVECARE/
‚îú‚îÄ backend/
‚îÇ  ‚îú‚îÄ api/                 # FastAPI (rotas, schemas, queries)
‚îÇ  ‚îú‚îÄ data/                # dados brutos e processados
‚îÇ  ‚îú‚îÄ database/
‚îÇ  ‚îÇ  ‚îú‚îÄ sql/              # DDL, importa√ß√£o e analytics
‚îÇ  ‚îÇ  ‚îî‚îÄ script/           # scripts de carga
‚îÇ  ‚îú‚îÄ script/              # pipeline de dados
‚îÇ  ‚îú‚îÄ .env
‚îÇ  ‚îî‚îÄ requirements.txt
‚îú‚îÄ frontend/
‚îÇ  ‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ public/
‚îÇ  ‚îú‚îÄ .env
‚îÇ  ‚îú‚îÄ package.json
‚îÇ  ‚îî‚îÄ vite.config.js
‚îî‚îÄ README.md
```
## ‚úÖ Requisitos do teste e como foram atendidos

### 1) Integra√ß√£o com API p√∫blica (ANS)

**Como foi feito:**
- Download autom√°tico dos **3 √∫ltimos trimestres** via `backend/script/download_data.py`.
- Extra√ß√£o dos ZIPs com `backend/script/extract_data.py`.
- Identifica√ß√£o de arquivos com ‚ÄúDespesas com Eventos/Sinistros‚Äù e normaliza√ß√£o com `backend/script/identify_files.py`.

**Trade-off t√©cnico (processamento incremental vs mem√≥ria):**
Escolhi **processamento incremental por arquivo**, porque os dados da ANS podem ser grandes e variados em formato. Isso reduz consumo de mem√≥ria e torna o pipeline mais resiliente a arquivos quebrados ou inconsistentes.

---

### 2) Consolida√ß√£o, valida√ß√£o e enriquecimento

**Como foi feito:**
- Consolida√ß√£o dos 3 trimestres com `backend/script/consolidar_despesas.py`.
- Valida√ß√£o de CNPJ e enriquecimento de dados cadastrais em `backend/script/transform_data.py`.

**Trade-offs t√©cnicos:**
1. **CNPJ inv√°lido:**  
   Optei por **marcar CNPJs inv√°lidos** (flag) e manter o registro, ao inv√©s de descartar.  
   *Pr√≥s:* preserva dados para auditoria e an√°lise posterior.  
   *Contras:* exige cuidado no consumo posterior.  

2. **Valores negativos ou zerados:**  
   Valores zerados/negativos s√£o tratados como ru√≠do ou inconsist√™ncia e n√£o entram nos c√°lculos agregados.

3. **Raz√£o social ausente:**  
   Preenchida com "DESCONHECIDO" para evitar registros incompletos.

4. **Join com cadastro de operadoras:**  
   Escolhi **join via CNPJ normalizado**, e para m√∫ltiplas ocorr√™ncias no cadastro, privilegiei a primeira ocorr√™ncia v√°lida (via deduplica√ß√£o).  
   *Justificativa:* evita explos√£o de registros e mant√©m o pipeline simples para um projeto de teste.

---

### 3) Banco de dados e an√°lise

**Escolhas t√©cnicas principais:**

- **Banco:** PostgreSQL >10.0  
  *Por qu√™:* oferece boa performance, suporte a tipos num√©ricos precisos (NUMERIC), e recursos maduros para an√°lise.

- **Normaliza√ß√£o (Trade-off):**  
  Escolhi **tabelas normalizadas** (operadoras, despesas_consolidadas e despesas_agregadas).  
  *Justificativa:* reduz redund√¢ncia em milh√µes de registros e facilita manuten√ß√£o.

- **Tipos de dados (Trade-off):**  
  Valores monet√°rios em **NUMERIC(18,2)** para evitar imprecis√£o de float.  
  Per√≠odos em **INTEGER/CHAR** para simplificar filtros e compara√ß√µes.

**Scripts SQL:**
- DDL: `backend/database/sql/create_tables.sql`
- Importa√ß√£o: `backend/database/sql/import_data.sql`
- Analytics: `backend/database/sql/analytics.sql`

---

### 4) API e Interface Web

**Backend (FastAPI)**
- Rotas implementadas:
  - `GET /api/operadoras` (pagina√ß√£o + busca)
  - `GET /api/operadoras/{cnpj}`
  - `GET /api/operadoras/{cnpj}/despesas`
  - `GET /api/estatisticas`

**Trade-offs t√©cnicos:**
- **Framework:** FastAPI  
  *Motivo:* rapidez na implementa√ß√£o, valida√ß√£o autom√°tica via Pydantic, documenta√ß√£o integrada.
- **Pagina√ß√£o:** Offset-based (`page`, `limit`)  
  *Motivo:* simples de implementar e adequado para o volume esperado.
- **Cache de estat√≠sticas:** cache em mem√≥ria por 5 minutos  
  *Motivo:* evita recalcular dados agregados com frequ√™ncia.
- **Resposta da API:** dados + metadados  
  *Motivo:* facilita pagina√ß√£o no frontend.

**Frontend (Vue 3)**
- P√°gina principal: tabela paginada + filtro por raz√£o social ou CNPJ.
- Gr√°fico de distribui√ß√£o de despesas por UF (Chart.js).
- P√°gina de detalhes com hist√≥rico de despesas.

**Trade-offs t√©cnicos no Frontend:**
- **Busca no servidor:** evita carregar volume grande no cliente.
- **Estado com composables:** mais simples que Vuex/Pinia para o escopo do projeto.
- **Tratamento de erros e loading:** mensagens espec√≠ficas de erro + estados visuais de carregamento.

---

## ‚úÖ Como executar (passo a passo)

> **Pr√©-requisitos:**  
> - Python 3.10+  
> - Node.js 18+  
> - PostgreSQL 10+  
> - Git (opcional, se o projeto j√° estiver baixado)

> **Importante:** abaixo est√° um passo a passo **bem detalhado**, para que consiga rodar tudo do zero.

### 0) (Opcional) Criar ambiente virtual do Python

Recomendado para isolar as depend√™ncias:

```bash
cd backend
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows
```

### 1) Instalar depend√™ncias do Backend

```bash
cd backend
pip install -r requirements.txt
```

### 1. Pipeline de dados

Esta etapa baixa os dados da ANS, extrai, filtra e gera os CSVs finais.

**Ordem exata dos scripts (execute um por vez):**

```bash
cd backend/script
python download_data.py
python extract_data.py
python identify_files.py
python consolidar_despesas.py
python transform_data.py
```

### 2. Banco de dados

Crie um banco vazio no PostgreSQL (exemplo: `intuitive_care`) e depois configure o arquivo `.env`.

1) Configure um arquivo `.env` em `backend/` com:

```
DB_HOST=localhost
DB_PORT=5432
DB_NAME=seu_banco
DB_USER=seu_usuario
DB_PASSWORD=sua_senha
```

2) Execute:

```bash
cd backend/database/script
python load_staging_and_run.py
```

---

### 3. Backend (API)

Com o banco pronto, suba a API:

```bash
cd backend
pip install -r requirements.txt
uvicorn api.main:app --reload
```

**Testar rapidamente:**
- Abra no navegador: `http://127.0.0.1:8000/health`
- Documenta√ß√£o autom√°tica: `http://127.0.0.1:8000/docs`

- **Teste via Postman:**  
  Voc√™ pode testar as rotas da API no Postman usando, por exemplo:  
  - `GET http://127.0.0.1:8000/api/operadoras?page=1&limit=10`  
  - `GET http://127.0.0.1:8000/api/operadoras/{cnpj}`  
  - `GET http://127.0.0.1:8000/api/operadoras/{cnpj}/despesas`  
  - `GET http://127.0.0.1:8000/api/estatisticas`

---

### 4. Frontend (Vue)

Agora suba o front:

```bash
cd frontend
npm install
npm run dev
```

**Acesso:**
- Normalmente em: `http://localhost:5173`

> Se a API estiver em outra porta/host, ajuste a vari√°vel `VITE_API_BASE_URL` no `.env` do front.

---

## ‚úÖ Considera√ß√µes finais

O objetivo foi atender todos os itens do teste com solu√ß√µes justificadas, mantendo organiza√ß√£o e clareza no fluxo de execu√ß√£o.  
Estou aberto a melhorias e discuss√µes t√©cnicas.
